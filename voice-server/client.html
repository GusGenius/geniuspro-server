<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GeniusPro Voice</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #0a0a0f;
            color: #e0e0e0;
            height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
        }

        .container {
            text-align: center;
            max-width: 600px;
            width: 90%;
        }

        h1 {
            font-size: 1.5rem;
            font-weight: 300;
            letter-spacing: 0.1em;
            color: #888;
            margin-bottom: 3rem;
        }

        h1 span { color: #7c6ff7; font-weight: 600; }

        /* Voice button */
        .voice-btn {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: 2px solid #333;
            background: #141420;
            cursor: pointer;
            position: relative;
            transition: all 0.3s ease;
            margin: 0 auto 2rem;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .voice-btn:hover { border-color: #7c6ff7; background: #1a1a2e; }

        .voice-btn.active {
            border-color: #7c6ff7;
            box-shadow: 0 0 30px rgba(124, 111, 247, 0.3);
            animation: pulse 2s ease-in-out infinite;
        }

        .voice-btn.listening {
            border-color: #4caf50;
            box-shadow: 0 0 30px rgba(76, 175, 80, 0.3);
        }

        .voice-btn.thinking {
            border-color: #ff9800;
            box-shadow: 0 0 30px rgba(255, 152, 0, 0.3);
        }

        .voice-btn.speaking {
            border-color: #2196f3;
            box-shadow: 0 0 30px rgba(33, 150, 243, 0.3);
            animation: pulse 1s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.05); }
        }

        .voice-btn svg { width: 40px; height: 40px; fill: #666; transition: fill 0.3s; }
        .voice-btn.active svg { fill: #7c6ff7; }
        .voice-btn.listening svg { fill: #4caf50; }
        .voice-btn.thinking svg { fill: #ff9800; }
        .voice-btn.speaking svg { fill: #2196f3; }

        /* Status */
        .status {
            font-size: 0.9rem;
            color: #666;
            margin-bottom: 2rem;
            min-height: 1.5em;
        }

        /* Transcript area */
        .transcript {
            text-align: left;
            max-height: 300px;
            overflow-y: auto;
            padding: 1rem;
            border: 1px solid #222;
            border-radius: 12px;
            background: #111118;
        }

        .transcript:empty { display: none; }

        .msg {
            padding: 0.5rem 0;
            border-bottom: 1px solid #1a1a25;
            line-height: 1.5;
        }

        .msg:last-child { border-bottom: none; }

        .msg.user { color: #aaa; }
        .msg.user::before { content: "You: "; color: #7c6ff7; font-weight: 600; }
        .msg.assistant { color: #ddd; }
        .msg.assistant::before { content: "GeniusPro: "; color: #4caf50; font-weight: 600; }
    </style>
</head>
<body>
    <div class="container">
        <h1><span>GeniusPro</span> Voice</h1>

        <div class="voice-btn" id="voiceBtn" onclick="toggleVoice()">
            <svg viewBox="0 0 24 24">
                <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zm-1-9c0-.55.45-1 1-1s1 .45 1 1v6c0 .55-.45 1-1 1s-1-.45-1-1V5zm6 6c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
            </svg>
        </div>

        <div class="status" id="status">Click to start voice mode</div>

        <div class="transcript" id="transcript"></div>
    </div>

    <script>
        let ws = null;
        let audioContext = null;
        let mediaStream = null;
        let processor = null;
        let isActive = false;
        let outputSampleRate = 24000;
        let audioQueue = [];
        let isPlaying = false;

        const btn = document.getElementById('voiceBtn');
        const status = document.getElementById('status');
        const transcript = document.getElementById('transcript');

        function setStatus(state, text) {
            status.textContent = text;
            btn.className = 'voice-btn' + (state ? ' ' + state : '');
        }

        async function toggleVoice() {
            if (isActive) {
                stopVoice();
            } else {
                await startVoice();
            }
        }

        async function startVoice() {
            try {
                // Get microphone
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: { sampleRate: 16000, channelCount: 1, echoCancellation: true, noiseSuppression: true }
                });

                // Audio context for mic processing
                audioContext = new AudioContext({ sampleRate: 16000 });
                const source = audioContext.createMediaStreamSource(mediaStream);

                // ScriptProcessor to capture audio chunks
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                processor.onaudioprocess = (e) => {
                    if (!ws || ws.readyState !== WebSocket.OPEN) return;
                    const float32 = e.inputBuffer.getChannelData(0);
                    const pcm16 = new Int16Array(float32.length);
                    for (let i = 0; i < float32.length; i++) {
                        pcm16[i] = Math.max(-32768, Math.min(32767, Math.round(float32[i] * 32768)));
                    }
                    ws.send(pcm16.buffer);
                };
                source.connect(processor);
                processor.connect(audioContext.destination);

                // Connect WebSocket
                const protocol = location.protocol === 'https:' ? 'wss:' : 'ws:';
                ws = new WebSocket(`${protocol}//${location.host}/v1/voice`);
                ws.binaryType = 'arraybuffer';

                ws.onopen = () => {
                    isActive = true;
                    setStatus('active', 'Voice mode on -- speak anytime');
                };

                ws.onmessage = (event) => {
                    if (typeof event.data === 'string') {
                        const msg = JSON.parse(event.data);
                        handleMessage(msg);
                    } else {
                        // Binary audio data from TTS
                        audioQueue.push(event.data);
                        if (!isPlaying) playAudioQueue();
                    }
                };

                ws.onclose = () => {
                    stopVoice();
                };

                ws.onerror = (err) => {
                    console.error('WebSocket error:', err);
                    setStatus('', 'Connection error');
                    stopVoice();
                };

            } catch (err) {
                console.error('Failed to start voice:', err);
                setStatus('', 'Microphone access denied');
            }
        }

        function stopVoice() {
            isActive = false;
            if (ws) { ws.close(); ws = null; }
            if (processor) { processor.disconnect(); processor = null; }
            if (audioContext) { audioContext.close(); audioContext = null; }
            if (mediaStream) { mediaStream.getTracks().forEach(t => t.stop()); mediaStream = null; }
            audioQueue = [];
            isPlaying = false;
            setStatus('', 'Click to start voice mode');
        }

        function handleMessage(msg) {
            switch (msg.type) {
                case 'config':
                    outputSampleRate = msg.output_sample_rate || 24000;
                    break;
                case 'status':
                    if (msg.state === 'listening') setStatus('listening', 'Listening...');
                    else if (msg.state === 'thinking') setStatus('thinking', 'Thinking...');
                    else if (msg.state === 'speaking') setStatus('speaking', 'Speaking...');
                    else if (msg.state === 'idle') setStatus('active', 'Voice mode on -- speak anytime');
                    break;
                case 'transcript':
                    addMessage('user', msg.text);
                    break;
                case 'response':
                    addMessage('assistant', msg.text);
                    break;
                case 'audio_end':
                    // Audio stream complete
                    break;
                case 'error':
                    setStatus('', 'Error: ' + msg.message);
                    break;
            }
        }

        function addMessage(role, text) {
            const div = document.createElement('div');
            div.className = 'msg ' + role;
            div.textContent = text;
            transcript.appendChild(div);
            transcript.scrollTop = transcript.scrollHeight;
        }

        async function playAudioQueue() {
            if (isPlaying) return;
            isPlaying = true;

            const playCtx = new AudioContext({ sampleRate: outputSampleRate });

            while (audioQueue.length > 0) {
                const chunk = audioQueue.shift();
                const pcm16 = new Int16Array(chunk);
                const float32 = new Float32Array(pcm16.length);
                for (let i = 0; i < pcm16.length; i++) {
                    float32[i] = pcm16[i] / 32768.0;
                }

                const buffer = playCtx.createBuffer(1, float32.length, outputSampleRate);
                buffer.getChannelData(0).set(float32);

                const source = playCtx.createBufferSource();
                source.buffer = buffer;
                source.connect(playCtx.destination);

                await new Promise(resolve => {
                    source.onended = resolve;
                    source.start();
                });
            }

            await playCtx.close();
            isPlaying = false;

            // Check if more audio arrived while playing
            if (audioQueue.length > 0) playAudioQueue();
        }
    </script>
</body>
</html>
